{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HeatMap Generation using Folium Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DkyVhLmooP64",
        "outputId": "52886904-5c6a-421f-93f0-5437409141ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import folium\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from folium.plugins import HeatMap, MeasureControl\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             roc_auc_score, ConfusionMatrixDisplay)\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import joblib\n",
        "\n",
        "\n",
        "# 1. Enhanced EDA Section\n",
        "\n",
        "def perform_eda(X, y):\n",
        "    data = X.copy()\n",
        "    data['label'] = y.values\n",
        "\n",
        "    # Select only numeric features for correlation analysis\n",
        "    numeric_features = data.select_dtypes(include=np.number).columns\n",
        "    excluded_columns_for_corr = ['latitude', 'longitude']\n",
        "    data_inter = data[numeric_features]\n",
        "    data_numeric = data_inter.drop(columns=excluded_columns_for_corr)\n",
        "\n",
        "    print(\"\\nBasic Statistics:\")\n",
        "    print(data.describe())\n",
        "\n",
        "    # Class distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x='label', data=data, palette='viridis')\n",
        "    plt.title('Class Distribution (0: Stable, 1: Landslide)')\n",
        "    plt.xticks([0, 1], ['Stable', 'Landslide'])\n",
        "    plt.savefig('Class Distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Feature correlations\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    corr_matrix = data_numeric.corr()\n",
        "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm',\n",
        "                mask=np.triu(np.ones_like(corr_matrix, dtype=bool)))\n",
        "    plt.title('Feature Correlation Matrix')\n",
        "    plt.savefig('Feature Correlartion Matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Geographical distribution\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.scatter(data['longitude'], data['latitude'],\n",
        "                c=data['label'], cmap='viridis', alpha=0.6)\n",
        "    plt.title('Geographical Distribution of Landslide Risk')\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.colorbar(label='Landslide Occurrence')\n",
        "    plt.savefig('Geographical Distribution of Landslide Risk.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# 2. Model Training & Evaluation\n",
        "def train_model(X_train, X_test, y_train, y_test):\n",
        "    # Model training\n",
        "    lgb_model = LGBMClassifier(random_state=42)\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01],\n",
        "        'max_depth': [4],\n",
        "        'min_data_in_leaf': [200],\n",
        "        'lambda_l1': [1.0],\n",
        "        'lambda_l2': [1.0],\n",
        "        'feature_fraction': [0.6]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(lgb_model, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    joblib.dump(best_model, 'landslide_model.pkl')\n",
        "\n",
        "    return best_model\n",
        "\n",
        "\n",
        "# 3. Probability Enhancement\n",
        "def enhance_probability(probs, new_min=0.1, new_max=0.95, power=1.5):\n",
        "    probs = np.array(probs)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled = scaler.fit_transform(probs.reshape(-1, 1)).flatten()\n",
        "    powered = np.power(scaled, power)\n",
        "    final_scaler = MinMaxScaler(feature_range=(new_min, new_max))\n",
        "    enhanced_probs = final_scaler.fit_transform(powered.reshape(-1, 1)).flatten()\n",
        "\n",
        "    return enhanced_probs\n",
        "\n",
        "\n",
        "# 4. Heatmap Generation\n",
        "def generate_heatmap(X_test, y_test, probabilities):\n",
        "    # Create analysis dataframe with ORIGINAL coordinates\n",
        "    analysis_df = X_test[['latitude', 'longitude']].copy()\n",
        "    analysis_df['label'] = y_test.values\n",
        "    analysis_df['probability'] = probabilities\n",
        "\n",
        "    # Filter and enhance landslide points\n",
        "    landslide_data = analysis_df[analysis_df['label'] == 1].copy()\n",
        "    original_probs = landslide_data['probability'].values\n",
        "    landslide_data['probability'] = enhance_probability(landslide_data['probability'])\n",
        "    enhanced_probs = landslide_data['probability'].values\n",
        "\n",
        "    # Verify transformation\n",
        "    print(f\"Original range: {original_probs.min():.2f} - {original_probs.max():.2f}\")\n",
        "    print(f\"Enhanced range: {enhanced_probs.min():.2f} - {enhanced_probs.max():.2f}\")\n",
        "\n",
        "    # Histogram Plot of probability distributions\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(original_probs, bins=20, color='blue', alpha=0.7)\n",
        "    plt.title('Original Probabilities')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(enhanced_probs, bins=20, color='red', alpha=0.7)\n",
        "    plt.title('Enhanced Probabilities')\n",
        "    plt.savefig('probability_distributions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Create map with proper coordinate validation\n",
        "    valid_coords = landslide_data[\n",
        "        (landslide_data['latitude'].between(-90, 90)) &\n",
        "        (landslide_data['longitude'].between(-180, 180))\n",
        "    ]\n",
        "\n",
        "    if valid_coords.empty:\n",
        "        raise ValueError(\"No valid geographic coordinates found after filtering\")\n",
        "\n",
        "    map_center = [\n",
        "        valid_coords['latitude'].median(),\n",
        "        valid_coords['longitude'].median()\n",
        "    ]\n",
        "\n",
        "    m = folium.Map(location=map_center, zoom_start=10,\n",
        "                  tiles='cartodbpositron', control_scale=True)\n",
        "\n",
        "    # Heatmap layer with string-formatted gradient keys\n",
        "    HeatMap(\n",
        "        valid_coords[['latitude', 'longitude', 'probability']].values.tolist(),\n",
        "        radius=15,\n",
        "        blur=20,\n",
        "        min_opacity=0.5,\n",
        "        gradient={'0.0': '#00ff00', '0.5': '#ffff00', '1.0': '#ff0000'},\n",
        "        max_zoom=15\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Add legend\n",
        "    legend_html = '''\n",
        "    <div style=\"\n",
        "        position: fixed;\n",
        "        bottom: 20px;\n",
        "        left: 20px;\n",
        "        width: 220px;\n",
        "        background-color: white;\n",
        "        border: 2px solid #ddd;\n",
        "        border-radius: 8px;\n",
        "        padding: 12px;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "        z-index: 9999;\n",
        "        font-family: Arial, sans-serif;\n",
        "    \">\n",
        "        <div style=\"\n",
        "            text-align: center;\n",
        "            font-weight: bold;\n",
        "            font-size: 16px;\n",
        "            color: #333;\n",
        "            margin-bottom: 10px;\n",
        "            padding-bottom: 10px;\n",
        "            border-bottom: 1px solid #eee;\n",
        "        \">\n",
        "            Landslide Risk\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center; margin-bottom: 8px;\">\n",
        "            <div style=\"\n",
        "                width: 25px;\n",
        "                height: 25px;\n",
        "                background-color: #00ff00;\n",
        "                opacity: 0.7;\n",
        "                margin-right: 10px;\n",
        "                border-radius: 4px;\n",
        "            \"></div>\n",
        "            <span style=\"color: #555;\">Low (0.1-0.3)</span>\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center; margin-bottom: 8px;\">\n",
        "            <div style=\"\n",
        "                width: 25px;\n",
        "                height: 25px;\n",
        "                background-color: #ffff00;\n",
        "                opacity: 0.7;\n",
        "                margin-right: 10px;\n",
        "                border-radius: 4px;\n",
        "            \"></div>\n",
        "            <span style=\"color: #555;\">Medium (0.3-0.7)</span>\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center;\">\n",
        "            <div style=\"\n",
        "                width: 25px;\n",
        "                height: 25px;\n",
        "                background-color: #ff0000;\n",
        "                opacity: 0.7;\n",
        "                margin-right: 10px;\n",
        "                border-radius: 4px;\n",
        "            \"></div>\n",
        "            <span style=\"color: #555;\">High (0.7-0.95)</span>\n",
        "        </div>\n",
        "    </div>\n",
        "    '''\n",
        "    m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "    # Add satellite layer with explicit attribute\n",
        "    folium.TileLayer(\n",
        "        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "        attr='Esri World Imagery',\n",
        "        name='Satellite View',\n",
        "        overlay=False,\n",
        "        control=True\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Save outputs\n",
        "    output_file = 'landslide_risk_map.html'\n",
        "    m.save(output_file)\n",
        "    valid_coords[['latitude', 'longitude', 'probability']].to_json(\n",
        "        'landslide_points.json', orient='records'\n",
        "    )\n",
        "    print(f\"Heatmap saved to {output_file}\")\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    X_train = pd.read_csv('final_X_train.csv')\n",
        "    X_test = pd.read_csv('final_X_test.csv')\n",
        "    y_train = pd.read_csv('y_train.csv').squeeze()\n",
        "    y_test = pd.read_csv('y_test.csv').squeeze()\n",
        "\n",
        "    # Perform EDA on test data\n",
        "    perform_eda(X_test, y_test)\n",
        "\n",
        "    # Separate coordinates before any processing\n",
        "    train_lat_lon = X_train[['latitude', 'longitude']].copy()\n",
        "    test_lat_lon = X_test[['latitude', 'longitude']].copy()\n",
        "\n",
        "    # Separate numeric and categorical columns (excluding coordinates)\n",
        "    numeric_columns = X_train.select_dtypes(include=[np.number]).columns.drop(['latitude', 'longitude']).tolist()\n",
        "    categorical_columns = X_train.select_dtypes(include=['category', 'object']).columns.tolist()\n",
        "\n",
        "    # Apply StandardScaler only to non-coordinate numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    X_train_numeric = scaler.fit_transform(X_train[numeric_columns])\n",
        "    X_test_numeric = scaler.transform(X_test[numeric_columns])\n",
        "\n",
        "    # Create scaled dataframes with original coordinates\n",
        "    X_train_scaled = pd.DataFrame(\n",
        "        X_train_numeric,\n",
        "        columns=numeric_columns,\n",
        "        index=X_train.index\n",
        "    ).join([train_lat_lon, X_train[categorical_columns]])\n",
        "\n",
        "    X_test_scaled = pd.DataFrame(\n",
        "        X_test_numeric,\n",
        "        columns=numeric_columns,\n",
        "        index=X_test.index\n",
        "    ).join([test_lat_lon, X_test[categorical_columns]])\n",
        "\n",
        "    # Convert categorical columns\n",
        "    for col in categorical_columns:\n",
        "        X_train_scaled[col] = X_train_scaled[col].astype('category')\n",
        "        X_test_scaled[col] = X_test_scaled[col].astype('category')\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "\n",
        "    # Generate predictions using original coordinates\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Generate reports\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Stable', 'Landslide']))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred,\n",
        "                                          display_labels=['Stable', 'Landslide'],\n",
        "                                          cmap='Blues')\n",
        "    plt.savefig('Confusion Matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Generate heatmap\n",
        "    risk_map = generate_heatmap(X_test, y_test, y_proba)\n",
        "    print(\"\\nLandslide risk map generated successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
