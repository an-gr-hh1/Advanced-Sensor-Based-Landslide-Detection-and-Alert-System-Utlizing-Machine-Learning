{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF21rxYVO0oH"
      },
      "source": [
        "# **DATA CLEANING**\n",
        "\n",
        "***Handling Missing Values:***\n",
        "\n",
        "  a) The code first checks for missing values and provides options to impute them using mean, median, mode, or KNN imputation.\n",
        "\n",
        "  b) It also allows you to remove rows or columns with excessive missing values.\n",
        "\n",
        "***Outlier Detection and Treatment:***\n",
        "\n",
        "  a) Outliers are detected using Z-scores and the Interquartile Range (IQR) method.\n",
        "\n",
        "  b) You can choose to remove outliers, cap them to a certain range, or apply transformations like log transformation.\n",
        "\n",
        "***Removing Inconsistencies:***\n",
        "\n",
        "  a) Duplicate rows are identified and removed.\n",
        "\n",
        "  b) Categorical variables are checked for inconsistent formatting or labeling errors.\n",
        "\n",
        "  c) Coordinates are validated to ensure they fall within the valid range for latitude and longitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tpjEBLbIUzk",
        "outputId": "8485d9db-7f64-4b18-ef8f-4b52292f30d9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy import stats\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('dataset_landslide_imputed.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Initial Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 1: Handle Missing Values\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Option 1: Impute missing values using mean, median, or mode\n",
        "# For numerical columns\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())  # or .median()\n",
        "\n",
        "# For categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
        "\n",
        "# Option 3: Remove rows/columns with excessive missing values\n",
        "# Drop rows with more than 50% missing values\n",
        "df = df.dropna(thresh=len(df.columns)//2, axis=0)\n",
        "# Drop columns with more than 50% missing values\n",
        "df = df.dropna(thresh=len(df)//2, axis=1)\n",
        "\n",
        "# Step 2: Outlier Detection and Treatment\n",
        "# Detect outliers using Z-scores\n",
        "z_scores = np.abs(stats.zscore(df[numerical_cols]))\n",
        "outliers = (z_scores > 3).any(axis=1)\n",
        "print(\"\\nOutliers detected using Z-scores:\")\n",
        "print(df[outliers])\n",
        "\n",
        "# Detect outliers using IQR\n",
        "Q1 = df[numerical_cols].quantile(0.25)\n",
        "Q3 = df[numerical_cols].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_iqr = ((df[numerical_cols] < (Q1 - 1.5 * IQR)) | (df[numerical_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
        "print(\"\\nOutliers detected using IQR:\")\n",
        "print(df[outliers_iqr])\n",
        "\n",
        "# Decide on treatment: Remove, cap, or transform outliers\n",
        "# Option 1: Remove outliers\n",
        "df = df[~outliers]\n",
        "\n",
        "# Step 3: Remove Inconsistencies\n",
        "# Check for duplicate entries\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "print(df[df.duplicated()])\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Check for inconsistent formatting or labeling errors in categorical variables\n",
        "print(\"\\nUnique Values in Categorical Columns:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"{col}: {df[col].unique()}\")\n",
        "\n",
        "latitude_col = 'latitude'\n",
        "longitude_col = 'longitude'\n",
        "\n",
        "# Define valid ranges for latitude and longitude\n",
        "valid_lat_range = (11.27, 11.98)\n",
        "valid_lon_range = (75.80, 76.44)\n",
        "\n",
        "# Filter out invalid coordinates\n",
        "df = df[(df[latitude_col].between(*valid_lat_range)) & (df[longitude_col].between(*valid_lon_range))]\n",
        "\n",
        "# Final cleaned dataset\n",
        "print(\"\\nCleaned Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Save the cleaned dataset to a new file\n",
        "df.to_csv('cleaned_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7iUxqWIh2iR"
      },
      "source": [
        "# **STRATIFIED SAMPLING**\n",
        "\n",
        "a) ***Stratified Sampling:***\n",
        "\n",
        "  The train_test_split function is used with the stratify=y parameter to ensure that the proportion of landslide/no-landslide cases is the same in both the training and testing sets as in the original dataset.\n",
        "\n",
        "b) ***Train-Test Split:***\n",
        "\n",
        "  The dataset is split into 80% training and 20% testing (test_size=0.2).\n",
        "\n",
        "  A random seed (random_state=42) is set for reproducibility.\n",
        "\n",
        "c) ***Distribution of Target Variable:***\n",
        "\n",
        "  The distribution of the target variable (label) is checked in both the training and testing sets to ensure balanced representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bb23D9uh1Oo",
        "outputId": "f77b97c6-dfc1-481e-ae13-20e4337768a0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('cleaned_dataset.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Dataset before splitting:\")\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop(columns=['label'])\n",
        "y = df['label']\n",
        "\n",
        "# Step 1: Split the dataset into training and testing sets using Stratified Sampling\n",
        "# Use a 80-20 split (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
        "\n",
        "# Display the shape of the resulting datasets\n",
        "print(\"\\nShape of Training Data:\", X_train.shape)\n",
        "print(\"Shape of Testing Data:\", X_test.shape)\n",
        "\n",
        "# Check the distribution of the target variable in the training and testing sets\n",
        "print(\"\\nDistribution of Target Variable in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nDistribution of Target Variable in Testing Set:\")\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n",
        "# Save the training and testing sets to new files\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "X_test.to_csv('X_test.csv', index=False)\n",
        "y_train.to_csv('y_train.csv', index=False)\n",
        "y_test.to_csv('y_test.csv', index=False)\n",
        "\n",
        "print(\"\\nTraining and testing sets saved to files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTMLK8-kXZdR"
      },
      "source": [
        "# **DATA TRANSFORMATION**\n",
        "\n",
        "***Feature Scaling:***\n",
        "\n",
        "  a) *Standardization (Z-score normalization):*\n",
        "\n",
        "        Transforms features to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "        Formula: z=(x−μ)σz=σ(x−μ)​\n",
        "\n",
        "        Suitable for features with Gaussian (normal) distribution.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn54j8zFXVCx",
        "outputId": "cd1eddc0-843f-4a15-e08b-5e178b62dc6b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the datasets\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv').squeeze()\n",
        "y_test = pd.read_csv('y_test.csv').squeeze()\n",
        "\n",
        "# Step 1: Feature Scaling\n",
        "# Select numerical columns for scaling (excluding latitude, longitude, and the target label)\n",
        "numerical_cols = X_train.select_dtypes(include=[np.number]).columns\n",
        "numerical_cols = numerical_cols.drop(['id', 'latitude', 'longitude'], errors='ignore')\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "print(\"\\nDataset after feature scaling:\")\n",
        "print(\"X_train head:\\n\", X_train.head())\n",
        "print(\"X_test head:\\n\", X_test.head())\n",
        "\n",
        "# Step 2: Convert categorical columns to the 'category' data type\n",
        "categorical_cols = ['geology', 'geomorphology', 'lulc']\n",
        "\n",
        "# Convert categorical columns to 'category' type\n",
        "for col in categorical_cols:\n",
        "    X_train[col] = X_train[col].astype('category')\n",
        "    X_test[col] = X_test[col].astype('category')\n",
        "\n",
        "print(\"\\nDataset after converting categorical columns to 'category' type:\")\n",
        "print(\"X_train head:\\n\", X_train.head())\n",
        "print(\"X_test head:\\n\", X_test.head())\n",
        "\n",
        "# Save the transformed datasets to new files\n",
        "X_train.to_csv('transformed_X_train.csv', index=False)\n",
        "X_test.to_csv('transformed_X_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3ND3ffDaQu1"
      },
      "source": [
        "# **DIMENTIONALITY REDUCTION**\n",
        "\n",
        "1. ***Correlation Analysis:***\n",
        "\n",
        "    a) A heatmap is created to visualize the correlation matrix of the dataset.\n",
        "\n",
        "    b) This helps identify highly correlated features, which can be redundant for modeling.\n",
        "\n",
        "\n",
        "2. ***Feature Selection:***\n",
        "\n",
        "    a) SHAP Feature Importance:\n",
        "\n",
        "            SHAP is an Explainability techniwque used to determine the feature contribution of a model. It is a game theory based approach. A LightGBM model is trained. SHAP Tree Explainer analyses the contribution of each feature in prediction.\n",
        "            Features are ranked based on their importance, and the results are visualized using a summary violin plot.\n",
        "\n",
        "    b) Categorical columns are converted to the 'category' data type. LightGBM can handle categorical features directly only if they are of type 'category'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mcda6e9H7ZFA",
        "outputId": "0f8d0b71-6a55-491a-d78d-6944280225d6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import lightgbm as lgb  # Import LightGBM\n",
        "import shap\n",
        "\n",
        "# Load the transformed datasets\n",
        "X_train = pd.read_csv('transformed_X_train.csv')\n",
        "X_test = pd.read_csv('transformed_X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv').squeeze()\n",
        "y_test = pd.read_csv('y_test.csv').squeeze()\n",
        "\n",
        "# Step 1: Exclude latitude and longitude for correlation analysis\n",
        "excluded_columns_for_corr = ['latitude', 'longitude', 'lulc', 'geology', 'geomorphology']\n",
        "X_for_corr = X_train.drop(columns=excluded_columns_for_corr)\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = X_for_corr.corr()\n",
        "\n",
        "# Plot a heatmap of the correlation matrix\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    cmap='Reds',\n",
        "    fmt=\".2f\",\n",
        "    linewidths=0.5,\n",
        "    annot_kws={\"size\": 10}\n",
        ")\n",
        "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.title(\"Correlation Heatmap\", fontsize=14, pad=20)\n",
        "plt.savefig(\"correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Step 2: Remove highly correlated features\n",
        "threshold = 0.83\n",
        "highly_correlated_features = set()\n",
        "\n",
        "# Identify pairs of highly correlated features\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
        "            colname_i = corr_matrix.columns[i]\n",
        "            colname_j = corr_matrix.columns[j]\n",
        "            print(f\"Highly correlated: {colname_i} and {colname_j} (corr = {corr_matrix.iloc[i, j]:.2f})\")\n",
        "            highly_correlated_features.add(colname_j)\n",
        "\n",
        "# Drop highly correlated features\n",
        "X_train_reduced = X_train.drop(columns=highly_correlated_features)\n",
        "X_test_reduced = X_test.drop(columns=highly_correlated_features)\n",
        "\n",
        "print(\"\\nFeatures dropped due to high correlation:\")\n",
        "print(highly_correlated_features)\n",
        "\n",
        "# Step 3: Exclude latitude and longitude for feature scaling\n",
        "excluded_columns_for_reduction = ['latitude', 'longitude', 'lulc', 'geology', 'geomorphology']\n",
        "X_train_reduced = X_train_reduced.drop(columns=excluded_columns_for_reduction)\n",
        "X_test_reduced = X_test_reduced.drop(columns=excluded_columns_for_reduction)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_reduced), columns=X_train_reduced.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test_reduced), columns=X_test_reduced.columns)\n",
        "\n",
        "# Step 4: Train LightGBM model\n",
        "print(\"\\nTraining LightGBM model...\")\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
        "lgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 5: Feature Selection using SHAP TreeExplainer\n",
        "print(\"\\nComputing feature importance using SHAP TreeExplainer...\")\n",
        "explainer = shap.TreeExplainer(lgb_model)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# Debugging: Check shape of SHAP values\n",
        "print(\"Shape of shap_values:\", np.array(shap_values).shape)\n",
        "\n",
        "# Get SHAP feature importance\n",
        "if isinstance(shap_values, list):  # Multi-class classification\n",
        "    shap_importance = np.abs(shap_values).mean(axis=(0, 1))\n",
        "else:  # Binary classification\n",
        "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "# Debugging: Check shapes\n",
        "print(\"Shape of shap_importance:\", shap_importance.shape)\n",
        "print(\"Number of features in X_train_scaled:\", len(X_train_scaled.columns))\n",
        "print(\"Features in X_train_scaled:\", X_train_scaled.columns)\n",
        "\n",
        "# Ensure shap_importance is 1-dimensional\n",
        "if len(shap_importance.shape) > 1:\n",
        "    raise ValueError(\"shap_importance is not 1-dimensional. Check the shape of shap_values.\")\n",
        "\n",
        "# Ensure the lengths match\n",
        "if len(shap_importance) != len(X_train_scaled.columns):\n",
        "    raise ValueError(f\"Mismatch in lengths: shap_importance has {len(shap_importance)} values, but X_train_scaled has {len(X_train_scaled.columns)} features.\")\n",
        "\n",
        "# Create a DataFrame for feature importance\n",
        "feature_importance_df = pd.DataFrame({'Feature': X_train_scaled.columns, 'Importance': shap_importance})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance DataFrame:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Step 6: Select top N features (including forced ones)\n",
        "top_n = 6\n",
        "selected_features = list(feature_importance_df.iloc[:top_n]['Feature'])\n",
        "\n",
        "# Force include specific features\n",
        "force_include_features = ['slope', 'ndvi', 'flow accumulation', 'twi', 'dist to riv', 'spi']\n",
        "for feature in force_include_features:\n",
        "    if feature in X_train_scaled.columns and feature not in selected_features:\n",
        "        selected_features.append(feature)\n",
        "\n",
        "# Update dataset with selected features\n",
        "X_train_selected = X_train_scaled[selected_features]\n",
        "X_test_selected = X_test_scaled[selected_features]\n",
        "\n",
        "print(\"\\nSelected Features using SHAP (including forced features):\")\n",
        "print(selected_features)\n",
        "\n",
        "# Step 7: Plot SHAP summary plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "if isinstance(shap_values, list):\n",
        "    shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train_scaled.columns, show=False)\n",
        "else:\n",
        "    shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train_scaled.columns, show=False)\n",
        "plt.savefig(\"shap_summary_plot.png\", dpi=300, bbox_inches=\"tight\")\n",
        "print(\"\\nSHAP summary plot saved as 'shap_summary_plot.png'\")\n",
        "\n",
        "# Step 8: Add latitude and longitude back to the final dataset\n",
        "X_train_final = pd.concat([X_train_selected, X_train[excluded_columns_for_reduction]], axis=1)\n",
        "X_test_final = pd.concat([X_test_selected, X_test[excluded_columns_for_reduction]], axis=1)\n",
        "\n",
        "# Save the final datasets to new files\n",
        "X_train_final.to_csv('final_X_train.csv', index=False)\n",
        "X_test_final.to_csv('final_X_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ITvBVri2P7"
      },
      "source": [
        "# **MACHINE LEARNING COMPARISON**\n",
        "\n",
        "  a) Model Used:\n",
        "\n",
        "      LightGBM\n",
        "\n",
        "  b) Hyperparameter Tuning:\n",
        "\n",
        "      Grid Search is used for hyperparameter tuning.\n",
        "\n",
        "  c) Evaluation Metrics:\n",
        "\n",
        "      ROC-AUC, Accuracy, Sensitivity (Recall), Specificity, F1-Score, Precision.\n",
        "\n",
        "  d) Confusion Matrix:\n",
        "\n",
        "      A confusion matrix is generated for each model and saved as an image.\n",
        "\n",
        "  e) ROC Curve:\n",
        "\n",
        "      ROC curves for all models are plotted and saved as an image.\n",
        "\n",
        "  f) k-Fold Cross-Validation:\n",
        "\n",
        "      Stratified k-fold cross-validation is used during hyperparameter tuning.\n",
        "\n",
        "  e) Performance Comparison:\n",
        "\n",
        "      A table comparing the performance of all models is generated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3rMvE53HzZe3",
        "outputId": "452b7be4-0038-4f97-8443-15c91f7f6d4c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, accuracy_score, confusion_matrix, f1_score,\n",
        "    recall_score, precision_score, roc_curve, auc, ConfusionMatrixDisplay, precision_recall_curve\n",
        ")\n",
        "from lightgbm import LGBMClassifier\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "X_train = pd.read_csv('final_X_train.csv')\n",
        "X_test = pd.read_csv('final_X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv').squeeze()\n",
        "y_test = pd.read_csv('y_test.csv').squeeze()\n",
        "\n",
        "# Separate numeric and categorical columns\n",
        "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "categorical_columns = X_train.select_dtypes(include=['category', 'object']).columns\n",
        "\n",
        "# Apply StandardScaler only to numeric columns\n",
        "scaler = StandardScaler()\n",
        "X_train_numeric = scaler.fit_transform(X_train[numeric_columns])\n",
        "X_test_numeric = scaler.transform(X_test[numeric_columns])\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_numeric, columns=numeric_columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_numeric, columns=numeric_columns, index=X_test.index)\n",
        "\n",
        "# Reattach the categorical features\n",
        "X_train = pd.concat([X_train_scaled, X_train[categorical_columns]], axis=1)\n",
        "X_test = pd.concat([X_test_scaled, X_test[categorical_columns]], axis=1)\n",
        "\n",
        "# Convert categorical columns to category dtype\n",
        "for col in categorical_columns:\n",
        "    X_train[col] = X_train[col].astype('category')\n",
        "    X_test[col] = X_test[col].astype('category')\n",
        "\n",
        "# Define evaluation metrics\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba):\n",
        "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_true)\n",
        "    metrics = {\n",
        "        'ROC-AUC': roc_auc_score(y_true, y_pred_proba),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Specificity': recall_score(y_true, y_pred, pos_label=0),\n",
        "        'F1-Score': f1_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Weighted_avg_auc': roc_auc_score(y_true, y_pred_proba, sample_weight=sample_weights)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# Define LightGBM model with initial hyperparameters\n",
        "lgb_model = LGBMClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'objective': ['binary'],\n",
        "    'learning_rate': [0.01],\n",
        "    'max_depth': [4],\n",
        "    'min_data_in_leaf': [200],\n",
        "    'lambda_l1': [1.0],\n",
        "    'lambda_l2': [1.0],\n",
        "    'feature_fraction': [0.6]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_lgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Save the trained model to a file using joblib\n",
        "joblib.dump(best_lgb_model, 'lgb_model.pkl')\n",
        "print(\"Model saved to 'lgb_model.pkl'.\")\n",
        "\n",
        "# Make predictions using the best model\n",
        "y_pred_train = best_lgb_model.predict(X_train)\n",
        "y_pred_test = best_lgb_model.predict(X_test)\n",
        "y_pred_proba_train = best_lgb_model.predict_proba(X_train)[:, 1]\n",
        "y_pred_proba_test = best_lgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model on training and testing data\n",
        "metrics_train = evaluate_model(y_train, y_pred_train, y_pred_proba_train)\n",
        "metrics_test = evaluate_model(y_test, y_pred_test, y_pred_proba_test)\n",
        "\n",
        "# Store results\n",
        "results = {\n",
        "    'LightGBM': {\n",
        "        'Training AUC': metrics_train['ROC-AUC'],\n",
        "        'Testing AUC': metrics_test['ROC-AUC'],\n",
        "        'Overall AUC': metrics_test['Weighted_avg_auc'],\n",
        "        'Training Accuracy': metrics_train['Accuracy'],\n",
        "        'Testing Accuracy': metrics_test['Accuracy'],\n",
        "        'Training F1-Score': metrics_train['F1-Score'],\n",
        "        'Testing F1-Score': metrics_test['F1-Score'],\n",
        "        'Training Recall': metrics_train['Recall'],\n",
        "        'Testing Recall': metrics_test['Recall'],\n",
        "        'Training Precision' : metrics_train['Precision'],\n",
        "        'Testing Precision' : metrics_test['Precision'],\n",
        "        'Training Specificity': metrics_train['Specificity'],\n",
        "        'Testing Specificity': metrics_test['Specificity']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Convert results to DataFrame format\n",
        "metrics_data = []\n",
        "for metric_name, value in results['LightGBM'].items():\n",
        "    split = metric_name.split()\n",
        "    if split[0] in ('Training', 'Testing', 'Overall'):\n",
        "        category = split[0]\n",
        "        metric = ' '.join(split[1:])\n",
        "    else:\n",
        "        category = 'Overall'\n",
        "        metric = metric_name\n",
        "    metrics_data.append({'Metric': metric, 'Category': category, 'Value': value})\n",
        "\n",
        "df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# 1. Grouped Bar Plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "ax = plt.subplot()\n",
        "metrics = df['Metric'].unique()\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.25\n",
        "\n",
        "for i, category in enumerate(['Training', 'Testing', 'Overall']):\n",
        "    values = df[df['Category'] == category]['Value'].values\n",
        "    if len(values) == len(metrics):\n",
        "        ax.bar(x + i*width, values, width, label=category)\n",
        "\n",
        "ax.set_xticks(x + width)\n",
        "ax.set_xticklabels(metrics, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.title('Model Performance Metrics Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.savefig('metrics_comparison_barplot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 2. Training vs Testing Scatter Plot\n",
        "train_metrics = []\n",
        "test_metrics = []\n",
        "labels = []\n",
        "\n",
        "for metric in ['Accuracy', 'F1-Score', 'Recall', 'Precision', 'Specificity', 'AUC']:\n",
        "    train_val = results['LightGBM'][f'Training {metric}']\n",
        "    test_val = results['LightGBM'][f'Testing {metric}']\n",
        "    train_metrics.append(train_val)\n",
        "    test_metrics.append(test_val)\n",
        "    labels.append(metric)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train_metrics, test_metrics, s=100, edgecolor='k', c='green')\n",
        "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "plt.xlabel('Training Score')\n",
        "plt.ylabel('Testing Score')\n",
        "plt.title('Training vs Testing Performance Comparison')\n",
        "plt.grid(True)\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    plt.annotate(label, (train_metrics[i], test_metrics[i]), \n",
        "                 xytext=(5, 5), textcoords='offset points')\n",
        "plt.tight_layout()\n",
        "plt.savefig('train_test_scatter.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 3. Radar Chart (Add this function before calling it)\n",
        "def create_radar_chart(categories, values1, values2, title):\n",
        "    N = len(categories)\n",
        "    angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
        "    values1 += values1[:1]\n",
        "    values2 += values2[:1]\n",
        "    angles += angles[:1]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "    ax.plot(angles, values1, 'o-', linewidth=2, label='Training')\n",
        "    ax.fill(angles, values1, alpha=0.25)\n",
        "    ax.plot(angles, values2, 'o-', linewidth=2, label='Testing')\n",
        "    ax.fill(angles, values2, alpha=0.25)\n",
        "    \n",
        "    ax.set_theta_offset(np.pi/2)\n",
        "    ax.set_theta_direction(-1)\n",
        "    ax.set_thetagrids(np.degrees(angles[:-1]), categories)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title(title, y=1.08)\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "    plt.savefig('radar_chart.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Create radar chart\n",
        "metrics_radar = ['Accuracy', 'F1-Score', 'Recall', 'Precision', 'Specificity', 'AUC']\n",
        "train_values = [results['LightGBM'][f'Training {m}'] for m in metrics_radar]\n",
        "test_values = [results['LightGBM'][f'Testing {m}'] for m in metrics_radar]\n",
        "create_radar_chart(metrics_radar, train_values, test_values, 'Performance Radar Chart')\n",
        "\n",
        "# 4. Heatmap\n",
        "heatmap_data = df.pivot(index='Category', columns='Metric', values='Value')\n",
        "plt.figure(figsize=(12, 4))\n",
        "sns.heatmap(heatmap_data, annot=True, cmap='Blues', fmt=\".2f\", vmin=0, vmax=1)\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.savefig('metrics_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix for training data\n",
        "cm_train = confusion_matrix(y_train, y_pred_train)\n",
        "tn_train, fp_train, fn_train, tp_train = cm_train.ravel()\n",
        "print(f\"Training Confusion Matrix for LightGBM:\")\n",
        "print(f\"TN: {tn_train}, FP: {fp_train}, FN: {fn_train}, TP: {tp_train}\")\n",
        "\n",
        "# Confusion Matrix for testing data\n",
        "cm_test = confusion_matrix(y_test, y_pred_test)\n",
        "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
        "print(f\"Testing Confusion Matrix for LightGBM:\")\n",
        "print(f\"TN: {tn_test}, FP: {fp_test}, FN: {fn_test}, TP: {tp_test}\")\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = best_lgb_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': range(X_train.shape[1]), 'Importance': feature_importance})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance Table:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Plot Feature Importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importance_df['Importance'], y=feature_importance_df['Feature'], palette='viridis')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('LightGBM Feature Importance')\n",
        "plt.savefig('feature_importance_lightgbm.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f'LightGBM (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_lightgbm.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba_test)\n",
        "pr_auc = auc(recall, precision)\n",
        "plt.plot(recall, precision, label=f'LightGBM (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "plt.savefig('pr_curve_lightgbm.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC Curve for both training and testing data\n",
        "plt.figure(figsize=(10, 8))\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_proba_train)\n",
        "roc_auc_train = auc(fpr_train, tpr_train)\n",
        "plt.plot(fpr_train, tpr_train, label=f'Training ROC (AUC = {roc_auc_train:.2f})', color='blue')\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc_test = auc(fpr_test, tpr_test)\n",
        "plt.plot(fpr_test, tpr_test, label=f'Testing ROC (AUC = {roc_auc_test:.2f})', color='green')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Train-Test Split')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_train_test.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot Confusion Matrix for LightGBM (Test Data)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=[\"No Landslide\", \"Landslide\"])\n",
        "disp.plot(cmap='Reds')\n",
        "plt.title('Confusion Matrix - LightGBM')\n",
        "plt.savefig('confusion_matrix_lightgbm_test.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
